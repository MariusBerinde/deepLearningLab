{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariusBerinde/deepLearningLab/blob/main/autoencoders_torch_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x79emQYkOm-I"
      },
      "source": [
        "# Exercise: Undercomplete Autoencoder with Convolutional Layers\n",
        "\n",
        "In this exercise, we will implement an undercomplete autoencoder using convolutional layers. We will use the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGJeejRWOm-L"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_20OSTaOm-N",
        "outputId": "63b3ee3c-9235-40e8-be13-59da797df5e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.backends.cuda.is_built():\n",
        "    device = torch.device('cuda')\n",
        "elif torch.backends.mps.is_built():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BNjeyCktQbDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to the description of the network.\n",
        "\n",
        "\n",
        "https://datacloud.di.unito.it/index.php/s/PdbYrWrBPs2tnac\n"
      ],
      "metadata": {
        "id": "tWxFWhH_QUyW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHZiMhZSOm-N",
        "outputId": "8f9027da-6d46-4843-aefb-20b51a6befec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 486kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.51MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.11MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mnist_train = MNIST('./data', download=True, transform=ToTensor())\n",
        "mnist_test = MNIST('./data', download=True, train=False, transform=ToTensor())\n",
        "\n",
        "\n",
        "mnist_train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
        "mnist_test_loader = DataLoader(mnist_test, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "eYqSaprMOm-O"
      },
      "outputs": [],
      "source": [
        "https://datacloud.di.unito.it/index.php/s/PdbYrWrBPs2tnac\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, z_size=3):\n",
        "       pass\n",
        "\n",
        "    def encode(self, x):\n",
        "        pass\n",
        "\n",
        "    def decode(self, z):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "    # Genrate a new random sample drawing representations form a uniform distribution\n",
        "    # and decoding them\n",
        "    def generate(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvmH4DmjOm-O"
      },
      "source": [
        "Training is nothing special and will be done with the Adam optimizer and MSE loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "EfxE3etMOm-O"
      },
      "outputs": [],
      "source": [
        "model = Model(z_size=10).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# loss function\n",
        "def loss_function(x_hat, x):\n",
        "    pass\n",
        "\n",
        "# Here the code to train the model\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa5l7iXJOm-P"
      },
      "source": [
        "# Plotting one reconstructed and one generated image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VZV3zlPOm-P"
      },
      "outputs": [],
      "source": [
        "img = model(mnist_test[0][0].to(device)).clip(0, 1).cpu().detach().numpy()\n",
        "plt.imshow(img.reshape(28, 28), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVSD371eOm-P"
      },
      "outputs": [],
      "source": [
        "gen = model.generate().clip(0, 1).cpu().detach().numpy().reshape(28, 28)\n",
        "plt.imshow(gen, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flJpkTXBOm-P"
      },
      "source": [
        "# Plotting a few reconstructed images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-io2l8YOm-Q"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.gray()\n",
        "\n",
        "imshape = (28, 28)\n",
        "preds = []\n",
        "\n",
        "for i in range(25):\n",
        "    with torch.no_grad():\n",
        "        preds.append(model(mnist_test[i][0].to(device)).cpu().float().numpy())\n",
        "\n",
        "for i in range(25):\n",
        "    ax = plt.subplot(5, 5, i + 1)\n",
        "    ax.imshow(preds[i].reshape(imshape), cmap=\"gray\")\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 2,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}